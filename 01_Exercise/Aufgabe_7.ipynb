{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvaaMy_bVgA9"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Aufgabe 7: Preprocessing & Pipelines\n",
        "Scikit-Learn ermöglicht es mittels Pipelines, verschiedene Vorverarbeitungsschritte (Normalisierung,\n",
        "Dimensionalitätsreduktion, etc.) mit einem Klassifier zu verbinden. In dieser Aufgabe beschäftigen\n",
        "wir uns mit dem Workflow von Datenverarbeitungsschritten mittels Pipelines.\\\n",
        "\n",
        "a) Laden Sie den Breast Cancer Wisconsin dataset unter:\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancerwisconsin/\n",
        "wdbc.data\\\n",
        "Dieses Dataset beinhaltet ein binary Label für Krebsdiagnostic (M=malignant, B=benign)\n",
        "und mehrere numerische Features, berechnet aus digitalisierten Bildern von Zellkernen.\n",
        "\n",
        "b) Nutzen Sie die sklearn.preprocessing.LabelEncoder um die binary Label in ein numerisches\n",
        "Attribut zu kodieren.\\\n",
        "\n",
        "c) Mit sklearn.cross_validation.train_test_split splitten Sie die Daten in Trainings (80%) und\n",
        "Testdaten (20%). Setzen Sie random_state=1.\n",
        "\n",
        "d) Als Preprocessingschritte nutzen Sie sklearn.preprocessing.StandardScaler für feature\n",
        "scaling und für Dimensionalitätsreduktion ein PCA mit sklearn.decomposition. PCA und mit\n",
        "n_components=2. Als Klassifikator nutzen Sie sklearn.linear_model.LogisticRegression mit\n",
        "random_state=1. Packen Sie alle Schritte in eine Pipeline (sklearn.pipeline.Pipeline).\n",
        "\n",
        "e) Testen Sie mittels pipeline.score die Genauigkeit des Modells. Sie sollten eine Genauigkeit\n",
        "von 0. 947 erreichen.\n",
        "\n",
        "f) Statt PCA nutzen Sie ein Recursive Feature Elimination (RFE) zur Feature-Auswahl\n",
        "(sklearn.feature_selection.RFECV). Wie viele und welche Features sind für die Klassifikation\n",
        "interessant? Welche (max.) Genauigkeit auf die Testdaten kann mit diesem Schritt (statt\n",
        "PCA) erreicht werden?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p34xe1yzVgBI"
      },
      "source": [
        "a) Laden Sie den Breast Cancer Wisconsin dataset unter:\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancerwisconsin/\n",
        "wdbc.data\\\n",
        "Dieses Dataset beinhaltet ein binary Label für Krebsdiagnostic (M=malignant, B=benign)\n",
        "und mehrere numerische Features, berechnet aus digitalisierten Bildern von Zellkernen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKnmzq5WVgBJ",
        "outputId": "9d1e3ee8-251d-4f8e-98fc-b2776ab15209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-10 19:07:22--  https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 124103 (121K) [application/x-httpd-php]\n",
            "Saving to: ‘wdbc.data.1’\n",
            "\n",
            "wdbc.data.1         100%[===================>] 121.19K   585KB/s    in 0.2s    \n",
            "\n",
            "2022-05-10 19:07:22 (585 KB/s) - ‘wdbc.data.1’ saved [124103/124103]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JQZMkAdeVgBK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aSSvSAEdVgBL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Exercise suggests to import sklearn.cross_validation.train_test_split\n",
        "# this is depricated for scikit-learn 1.0.2\n",
        "# suggestion: instead of \n",
        "# from sklearn.cross_validation import train_test_split \n",
        "# use:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA \n",
        "\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.svm import SVR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jx1cbMYdVgBL"
      },
      "outputs": [],
      "source": [
        "filename = 'wdbc.data'\n",
        "\n",
        "columns = ['id', 'diagnosis']\n",
        "df_original = pd.read_csv(filename, header=None) \n",
        "###0 identifier, 1 diagnosis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88sgFUGPVgBM"
      },
      "source": [
        "b) Nutzen Sie die sklearn.preprocessing.LabelEncoder um die binary Label in ein numerisches\n",
        "Attribut zu kodieren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EGJRAGuEVgBM",
        "outputId": "5c090dcf-1432-44c8-893a-2ee4267020b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        2      3       4       5        6        7        8        9       10  \\\n",
              "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
              "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
              "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
              "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
              "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
              "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
              "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
              "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
              "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
              "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
              "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
              "\n",
              "          11  ...      22     23      24      25       26       27      28  \\\n",
              "0    0.07871  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
              "1    0.05667  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
              "2    0.05999  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
              "3    0.09744  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
              "4    0.05883  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
              "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
              "564  0.05623  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
              "565  0.05533  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
              "566  0.05648  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
              "567  0.07016  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
              "568  0.05884  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
              "\n",
              "         29      30       31  \n",
              "0    0.2654  0.4601  0.11890  \n",
              "1    0.1860  0.2750  0.08902  \n",
              "2    0.2430  0.3613  0.08758  \n",
              "3    0.2575  0.6638  0.17300  \n",
              "4    0.1625  0.2364  0.07678  \n",
              "..      ...     ...      ...  \n",
              "564  0.2216  0.2060  0.07115  \n",
              "565  0.1628  0.2572  0.06637  \n",
              "566  0.1418  0.2218  0.07820  \n",
              "567  0.2650  0.4087  0.12400  \n",
              "568  0.0000  0.2871  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4d74115-fcf3-44e9-a6cb-4d81b12e834d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>...</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4d74115-fcf3-44e9-a6cb-4d81b12e834d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4d74115-fcf3-44e9-a6cb-4d81b12e834d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4d74115-fcf3-44e9-a6cb-4d81b12e834d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(df_original[1])\n",
        "df = df_original.copy()\n",
        "labels = le.transform(df_original[1])\n",
        "# to transform labels back to original use: le.inverse_transform() \n",
        "\n",
        "df = df_original.copy()\n",
        "\n",
        "# remove labels and original identifier\n",
        "# although not specified explicitly the unique sample identifier should not contain any \n",
        "# important data for classification and is hence removed. Also labels shouldn't be contained in the input dataframe.\n",
        "df = df.drop([0,1], axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEiZPznzVgBN"
      },
      "source": [
        "c) Mit sklearn.cross_validation.train_test_split splitten Sie die Daten in Trainings (80%) und\n",
        "Testdaten (20%). Setzen Sie random_state=1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n40gNLFvVgBN"
      },
      "outputs": [],
      "source": [
        "# sklearn.cross_validation.train_test_split is depricated for scikit-learn 1.0.2\n",
        "# instead sklearn.model_selection.train_test_split was used \n",
        "\n",
        "# split in train 80% and testdata\n",
        "X_train, X_test, y_train, y_test  = train_test_split(df, labels, random_state=1, test_size=0.20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXC97jK9VgBN"
      },
      "source": [
        "d) Als Preprocessingschritte nutzen Sie sklearn.preprocessing.StandardScaler für feature\n",
        "scaling und für Dimensionalitätsreduktion ein PCA mit sklearn.decomposition. PCA und mit\n",
        "n_components=2. Als Klassifikator nutzen Sie sklearn.linear_model.LogisticRegression mit\n",
        "random_state=1. Packen Sie alle Schritte in eine Pipeline (sklearn.pipeline.Pipeline)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUlLP6hHVgBO",
        "outputId": "10b45efd-d555-4469-a867-2952ee0a4927"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA(n_components=2)),\n",
              "                ('classifier', LogisticRegression(random_state=1))])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "steps = [('scaler', StandardScaler()), \n",
        "         ('pca', PCA(n_components=2)), \n",
        "         ('classifier', LogisticRegression(random_state=1))]\n",
        "pipe = Pipeline(steps)\n",
        "\n",
        "pipe.fit(X=X_train, y=y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX-FXEVbVgBO"
      },
      "source": [
        "e) Testen Sie mittels pipeline.score die Genauigkeit des Modells. Sie sollten eine Genauigkeit\n",
        "von 0. 947 erreichen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_86608TiVgBP",
        "outputId": "7158faa6-827b-4816-d2e4-6d64cc3d28b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9473684210526315"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "pipe.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "212swDWxVgBP"
      },
      "source": [
        "f) Statt PCA nutzen Sie ein Recursive Feature Elimination (RFE) zur Feature-Auswahl\n",
        "(sklearn.feature_selection.RFECV). Wie viele und welche Features sind für die Klassifikation\n",
        "interessant? Welche (max.) Genauigkeit auf die Testdaten kann mit diesem Schritt (statt\n",
        "PCA) erreicht werden?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aDNQiNcVgBQ",
        "outputId": "033f4507-9f87-48dd-aa98-9e8b346a0679"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('RFE', RFECV(estimator=SVR(kernel='linear'))),\n",
              "                ('classifier', LogisticRegression(random_state=1))])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "estimator = SVR(kernel=\"linear\")\n",
        "selector = RFECV(estimator)\n",
        "\n",
        "steps_rfe = [('scaler', StandardScaler()), \n",
        "         ('RFE', selector), \n",
        "         ('classifier', LogisticRegression(random_state=1))]\n",
        "\n",
        "pipe_rfe = Pipeline(steps_rfe)\n",
        "\n",
        "pipe_rfe.fit(X=X_train, y=y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cClGTyoVgBR",
        "outputId": "fa25993e-80b3-4f8a-b5dc-8e48a8054224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wieviele: 25\n",
            "Welche: [ True  True  True  True  True  True  True  True False  True  True  True\n",
            "  True  True  True  True  True  True  True False  True False  True  True\n",
            " False  True  True  True False  True]\n",
            "Welche: (ranking)[1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 4 1 6 1 1 5 1 1 1 2 1]\n"
          ]
        }
      ],
      "source": [
        "# Wie viele und welche Features sind für die Klassifikation interessant?\n",
        "\n",
        "print('Wieviele: '+ str(selector.support_.sum()))\n",
        "print('Welche: ' + str(selector.support_))\n",
        "print('Welche: (ranking)' + str(selector.ranking_ ))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es werden 25 Features selektiert. Davon ist insbesondere Nummer 9 (Symmetrie) sowie einige der Features die mit Feature Engineering erzeugt wurden uninteressant. Für einge genauere Beschreibung der einzelnen Features siehe: https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names"
      ],
      "metadata": {
        "id": "ef6-1d6hW4it"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9e-iu7UVgBR",
        "outputId": "b4ca261e-9b23-4fdc-cf2c-0dcb906f2532"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9736842105263158"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Welche (max.) Genauigkeit auf die Testdaten kann mit diesem Schritt (statt PCA) erreicht werden?\n",
        "pipe_rfe.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es wird eine Geauigkeit von 0.9736842105263158 erreicht."
      ],
      "metadata": {
        "id": "kOMHxwnWWxvK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w2GuY1WSVgBS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2Lk5TwgxVgBS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1cwJPiQZVgBS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rucZTJpLVgBS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f1rTCjlMVgBT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UlTqgNsDVgBT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "884-Loa3VgBU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jtEMD-GKVgBU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yMiW-oNHVgBU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZMWcnpj3VgBV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jzyZkZNEVgBV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Aufgabe_7.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}