{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e96OGEl07oXG"
   },
   "source": [
    "# Mount Google Drive\n",
    "In this example, the data is saved in the folder of personal google drive.\n",
    "\n",
    "First you have to upload the data to your google drive, then connect the drive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skgwbdhJ2aEl"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CG_U0Y9w72ze"
   },
   "source": [
    "# Install Python Packages\n",
    "Although most of the commonly used Python libraries are pre-installed, new libraries can be installed using the below packages:\n",
    "\n",
    "!pip install [package name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vGHEFxAJ9oqF"
   },
   "outputs": [],
   "source": [
    "!pip install tsfresh\n",
    "# tsfresh is a python package, which automatically calculates a large number of time series characteristics (features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A67lPTNHJkGs"
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boLQLTsdJjY6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['ytick.labelsize'] = \"x-large\"\n",
    "plt.rcParams['xtick.labelsize'] = \"x-large\"\n",
    "plt.rcParams['axes.labelsize'] = \"x-large\"\n",
    "plt.rcParams['figure.titlesize'] = \"x-large\"\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wb00bcxu9tih"
   },
   "source": [
    "# Data Description\n",
    "C-MAPSS data set which contains turbofan engine degradation data is a widely used prognostic benchmark data for predicting the Remaining useful life (RUL). This data set is simulated by the tool Commercial Modular Aero Propulsion System Simulation (C-MAPSS) developed by NASA. Run to failure simulations were performed for engines with varying degrees of initial wear but in a healthy state. During each cycle in the simulation, one sample of all 21 sensors such as physical core speed, temperature at fan inlet and pressure at fan inlet etc will be recorded once. As the simulation progresses, the performance of the turbofan engine degrades until it loses functionality. \n",
    "\n",
    "C-MAPSS data consists of four sub-data sets with different operational conditions and fault patterns. \n",
    "\n",
    "|         Dataset        | FD001 | FD002 | FD003 | FD004 |\n",
    "|:----------------------:|:-----:|:-----:|:-----:|:-----:|\n",
    "|      Training set      |  100  |  260  |  100  |  249  |\n",
    "|        Test set        |  100  |  259  |  100  |  248  |\n",
    "| Operational conditions |   1   |   6   |   1   |   6   |\n",
    "| Fault conditions       | 1     | 1     | 2     | 2     |\n",
    "\n",
    "\n",
    "As shown Table above, each sub-data set has been split into a training set and a test set. The training sets contain sensor records for all cycles in the run to failure simulation. Unlike the training sets, the test sets only contain partial temporal sensor records which stopped at a time prior to the failure. The task is to predict the RUL of each engine in the test sets by using the training sets with the given sensor records. The corresponding RUL to test sets has been provided. With this, the performance of the model can be verified. \n",
    "\n",
    "The data provieded as text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:\n",
    "\n",
    "unit number\n",
    "\n",
    "time, in cycles\n",
    "\n",
    "operational setting 1\n",
    "\n",
    "operational setting 2\n",
    "\n",
    "operational setting 3\n",
    "\n",
    "sensor measurement 1\n",
    "\n",
    "sensor measurement 2 \n",
    "\n",
    "sensor measurement 3 \n",
    "\n",
    "...\n",
    "\n",
    "sensor measurement 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLw-w1TDE9Zo"
   },
   "source": [
    "# Data Exploration and Preparation\n",
    "take FD001 as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAmDXiZU2mkK"
   },
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "Path_to_data = \"drive/My Drive/PSDA2020/\"\n",
    "\n",
    "column_name = ['engine_id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "               's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "               's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "# training data set\n",
    "train_FD001 = pd.read_table(Path_to_data+\"train_FD001.txt\", header=None, delim_whitespace=True)\n",
    "train_FD001.columns = column_name\n",
    "\n",
    "# test data set\n",
    "test_FD001 = pd.read_table(Path_to_data+\"test_FD001.txt\", header=None, delim_whitespace=True)\n",
    "test_FD001.columns = column_name\n",
    "\n",
    "# RUL for test data set\n",
    "RUL_FD001 = pd.read_table(Path_to_data+\"RUL_FD001.txt\", header=None, delim_whitespace=True)\n",
    "\n",
    "train_FD001.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2R6-hIDIJZu"
   },
   "source": [
    "In this sub dataset we have **100** engines (engine_id) which are monitored over time (cycle). Each engine had operational_settings and sensor_measurements recorded for each cycle. The RUL is the amount of cycles an engine has left before it needs maintenance. What makes this data set special is that the engines run all the way until failure, giving us precise RUL information for every engine at every point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7z2IzRdSIdDk"
   },
   "outputs": [],
   "source": [
    "def add_RUL(col):\n",
    "    # Reverse the cycle evolution, where remaining time of a machine is 0 at the failure.\n",
    "    # It is assumed here that the state of the machine is linearly deteriorating\n",
    "    return col[::-1]-1\n",
    "# Calculate RUL for each time point of each engine  \n",
    "train_FD001['rul'] = train_FD001[['engine_id', 'cycle']].groupby('engine_id').transform(add_RUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQMbZSIAE1aU"
   },
   "source": [
    "**Is there any other way to define target lable (RUL) ?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfBy89S6P4kJ"
   },
   "outputs": [],
   "source": [
    "# Visualize the RUL curve of some engines (1,2,3,4,5,6)\n",
    "g = sns.PairGrid(data=train_FD001.reset_index().query('engine_id < 7') ,\n",
    "                 x_vars=[\"index\"],\n",
    "                 y_vars=['rul'],\n",
    "                 hue=\"engine_id\", height=3, aspect=2.5)\n",
    "\n",
    "g = g.map(plt.plot, alpha=1)\n",
    "g = g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YfEPxGjLm5K"
   },
   "outputs": [],
   "source": [
    "# Visualize some sensor curves of some engines \n",
    "g = sns.PairGrid(data=train_FD001.query('engine_id < 5') ,\n",
    "                 x_vars=[\"rul\"],\n",
    "                 y_vars=['s1','s2'],\n",
    "                 hue=\"engine_id\", height=3, aspect=2.5)\n",
    "\n",
    "g = g.map(plt.plot, alpha=1)\n",
    "g = g.add_legend()\n",
    "\n",
    "# As shown in the figure, some sensors are not related to RUL. \n",
    "# The values of some sensors change with the state of the machine. \n",
    "# Visualization can help filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6kbeakQcTv5n"
   },
   "outputs": [],
   "source": [
    "# Distribution of maximum life cycle\n",
    "train_FD001[['engine_id', 'rul']].groupby('engine_id').apply(np.max)[\"rul\"].hist(bins=20)\n",
    "plt.xlabel(\"max life cycle\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5urHHKAeFKY7"
   },
   "source": [
    "**Can you do more visualizationï¼Ÿ Please give a simple summary or explanation for each visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwWNM2GQWE-Q"
   },
   "outputs": [],
   "source": [
    "# prepare the data and normalization\n",
    "train_y = train_FD001['rul']\n",
    "features = train_FD001.columns.drop(['engine_id', 'cycle', 'rul'])\n",
    "train_x = train_FD001[features]\n",
    "test_x = test_FD001[features]\n",
    "\n",
    "\n",
    "# z score normalization\n",
    "mean = train_x.mean()\n",
    "std = train_x.std()\n",
    "std.replace(0, 1, inplace=True)\n",
    "\n",
    "train_x = (train_x - mean) / std\n",
    "test_x = (test_x - mean) / std\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "x, y = shuffle(train_x, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lNk2ycyuFrHq"
   },
   "source": [
    "**Here only the values at each time point (cycle) are used to predict the RUL. Temporal relationship is ignored. How to use Temporal relationship?**\n",
    "\n",
    "tip : Sliding Window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZPWL4IWVJFV"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alPz0At-SyVz"
   },
   "outputs": [],
   "source": [
    "# Random Forest with default Hyper parameters\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(x,y)\n",
    "rf_prediction = rf_model.predict(train_x)\n",
    "plt.plot(rf_prediction[:500])\n",
    "plt.plot(train_FD001[\"rul\"][:500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDzgpXQcLGsC"
   },
   "outputs": [],
   "source": [
    "# Lasso model with default Hyper parameters\n",
    "ls_model = LassoCV()\n",
    "ls_model.fit(x,y)\n",
    "ls_prediction = ls_model.predict(train_x)\n",
    "plt.plot(ls_prediction[:500])\n",
    "plt.plot(train_FD001[\"rul\"][:500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I12xg2WDK0pD"
   },
   "source": [
    "**How to tune hyperparameters and select models?** \n",
    "\n",
    "**Neural network model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0iQ_3EzOVeAe"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ie-jLvidHZ9O"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Since only the value at one time point is used, it can be seen that a lot of data in the test set is not used\n",
    "\n",
    "test_x['engine_id'] = test_FD001['engine_id']\n",
    "test_input = []\n",
    "for id in test_x['engine_id'].unique():\n",
    "  \n",
    "  test_input.append(test_x[test_x['engine_id']==id].iloc[-1,:-1].values)\n",
    "\n",
    "test_input = np.array(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJ1HI43iHZ65"
   },
   "outputs": [],
   "source": [
    "# Random forest\n",
    "\n",
    "rf_test_prediction = rf_model.predict(test_input)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(rf_test_prediction, RUL_FD001.values.reshape(-1)))\n",
    "\n",
    "print(\"The RMSE of random forest on test dataset FD001 is \",rf_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YW_6FmUHZ4T"
   },
   "outputs": [],
   "source": [
    "# Lasso model\n",
    "\n",
    "ls_test_prediction = ls_model.predict(test_input)\n",
    "\n",
    "ls_rmse = np.sqrt(mean_squared_error(ls_test_prediction, RUL_FD001.values.reshape(-1)))\n",
    "\n",
    "print(\"The RMSE of Lasso model on test dataset FD001 is \",ls_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "myaoeDxY09PE"
   },
   "source": [
    "**What is your best result? If the used model is interpretable, what other conclusions can be summarized**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C-MAPSS RUL Estimation.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
